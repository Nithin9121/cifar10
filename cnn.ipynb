{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open(\"D:\\\\python codes\\\\ML\\\\data1\\\\cifar10\\\\train\\\\airplane\\\\29_airplane.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data= tf.keras.utils.image_dataset_from_directory(\n",
    "    \"D:\\\\python codes\\\\ML\\\\data1\\\\cifar10\\\\train\",\n",
    "    image_size=(32,32),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model=tf.keras.Sequential([\n",
    "    layers.Conv2D(9,3,padding=\"same\",activation=\"leaky_relu\",input_shape=(32,32,3)),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(18,3,padding=\"same\",activation=\"leaky_relu\"),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(36,3,padding=\"same\",activation=\"leaky_relu\"),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10),\n",
    "    layers.Softmax()\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 9)         252       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 9)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 18)        1476      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 18)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 36)          5868      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 36)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,174\n",
      "Trainable params: 45,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.build(input_shape=(1,32,32,3))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 38s 37ms/step - loss: 1.5879 - accuracy: 0.4233\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.2877 - accuracy: 0.5413\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1378 - accuracy: 0.6008\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.0378 - accuracy: 0.6355\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.9624 - accuracy: 0.6630\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9124 - accuracy: 0.6815\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8676 - accuracy: 0.6956\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8241 - accuracy: 0.7142\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7938 - accuracy: 0.7227\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7589 - accuracy: 0.7354\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7291 - accuracy: 0.7465\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7031 - accuracy: 0.7543\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6765 - accuracy: 0.7638\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6520 - accuracy: 0.7724\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6312 - accuracy: 0.7791\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.6088 - accuracy: 0.7858\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.5921 - accuracy: 0.7940\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.5682 - accuracy: 0.8006\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.5554 - accuracy: 0.8043\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.5354 - accuracy: 0.8128\n",
      "(50000, 32, 32, 3) (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "for features,labels in data:\n",
    "    features=tf.divide(features,255)\n",
    "    labels=tf.one_hot(labels,10)\n",
    "    record=cnn_model.fit(features,labels,batch_size=50,epochs=20)\n",
    "    print(features.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=cnn_model.save(\"cifar10_img_pred.h5\",save_format=\"h5\")\n",
    "model=tf.keras.models.load_model(\"cifar10_img_pred.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "611b6fa4c1e78b0db9b920c418339984a71f9699046d931016998444730996ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
