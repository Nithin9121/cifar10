{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 9)         252       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 9)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 18)        1476      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 18)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 36)          5868      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 36)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,174\n",
      "Trainable params: 45,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"D:\\\\python codes\\\\ML\\\\data1\\\\cifar10_img_pred.h5\")\n",
    "classes=[\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"sheep\",\n",
    "    \"truck\"    \n",
    "]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open(\"D:\\\\python codes\\\\ML\\\\data1\\\\cifar10\\\\train\\\\airplane\\\\77_airplane.png\")\n",
    "img=img.resize((32,32))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<PIL.Image.Image image mode=RGB size=32x32 at 0x1D3252FCFD0>) with an unsupported type (<class 'PIL.Image.Image'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mreshape(tf\u001b[39m.\u001b[39;49mconstant(img)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m      2\u001b[0m preds\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(test,verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m index\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(tf\u001b[39m.\u001b[39mwhere(preds\u001b[39m==\u001b[39m preds\u001b[39m.\u001b[39mmax())[\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<PIL.Image.Image image mode=RGB size=32x32 at 0x1D3252FCFD0>) with an unsupported type (<class 'PIL.Image.Image'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "test=tf.reshape(tf.constant(img)/255, (-1,32,32,3))\n",
    "preds=model.predict(test,verbose=False)\n",
    "index=int(tf.where(preds== preds.max())[0],[1])\n",
    "preds=classes[index]\n",
    "confidence=round(preds.max()*100,2)\n",
    "print(preds.title().confidence,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "611b6fa4c1e78b0db9b920c418339984a71f9699046d931016998444730996ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
