{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 9)         252       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 9)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 18)        1476      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 18)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 36)          5868      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 36)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,174\n",
      "Trainable params: 45,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"D:\\\\python codes\\\\ML\\\\data1\\\\cifar10_img_pred.h5\")\n",
    "classes=[\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"sheep\",\n",
    "    \"truck\"    \n",
    "]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open(\"D:\\\\python codes\\\\ML\\\\data1\\\\cifar10\\\\train\\\\airplane.jpg\")\n",
    "img=img.resize((32,32))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<PIL.Image.Image image mode=RGB size=32x32 at 0x20C09E02050>) with an unsupported type (<class 'PIL.Image.Image'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m img\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mresize((\u001b[39m32\u001b[39m,\u001b[39m32\u001b[39m))\n\u001b[0;32m      3\u001b[0m img\n\u001b[1;32m----> 4\u001b[0m test\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mreshape(tf\u001b[39m.\u001b[39;49mconstant(img)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m      5\u001b[0m preds\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(test,verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m index\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(tf\u001b[39m.\u001b[39mwhere(preds\u001b[39m==\u001b[39m preds\u001b[39m.\u001b[39mmax())[\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\A.NITHIN KUMAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<PIL.Image.Image image mode=RGB size=32x32 at 0x20C09E02050>) with an unsupported type (<class 'PIL.Image.Image'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "test=tf.reshape(tf.constant(img)/255, (-1,32,32,3))\n",
    "preds=model.predict(test,verbose=False)\n",
    "index=int(tf.where(preds== preds.max())[0],[1])\n",
    "preds=classes[index]\n",
    "confidence=round(preds.max()*100,2)\n",
    "print(preds.title().confidence,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "611b6fa4c1e78b0db9b920c418339984a71f9699046d931016998444730996ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
